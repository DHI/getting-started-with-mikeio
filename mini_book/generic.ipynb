{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generic dfs processing\r\n",
    "Tools and methods that applies to any type of dfs files. \r\n",
    "\r\n",
    "The generic tools are useful for common data processing tasks, where detailed configuration is not necessary. \r\n",
    "\r\n",
    "* mikeio.read()\r\n",
    "* mikeio.generic: methods that read any dfs file and outputs a new dfs file of the same type\r\n",
    "   - concat: Concatenates files along the time axis  \r\n",
    "   - scale: Apply scaling to any dfs file\r\n",
    "   - sum: Sum two dfs files \r\n",
    "   - diff: Calculate difference between two dfs files\r\n",
    "   - extract: Extract timesteps and/or items to a new dfs file\r\n",
    "\r\n",
    "The generic methods works on larger-than-memory files as they process one time step at a time. This can however make them in-efficient for dfs0 processing! "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Concatenation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import mikeio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take a look at these two files with overlapping timesteps."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t1 = mikeio.read(\"data/tide1.dfs1\")\r\n",
    "t1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t2 = mikeio.read(\"data/tide2.dfs1\")\r\n",
    "t2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot one of the points along the line."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(t1.time,t1.data[0][:,1], label=\"File 1\")\r\n",
    "plt.plot(t2.time,t2.data[0][:,1],'k+', label=\"File 2\")\r\n",
    "plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import mikeio.generic\r\n",
    "\r\n",
    "mikeio.generic.concat(infilenames=[\"data/tide1.dfs1\",\r\n",
    "                                   \"data/tide2.dfs1\"],\r\n",
    "                     outfilename=\"concat.dfs1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c = mikeio.read(\"concat.dfs1\")\r\n",
    "plt.plot(c.time,c.data[0][:,1])\r\n",
    "c"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract time steps or items"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "infile = \"data/tide1.dfs1\"\r\n",
    "mikeio.generic.extract(infile, \"extracted.dfs1\", start='2019-01-02')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e = mikeio.read(\"extracted.dfs1\")\r\n",
    "e"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "infile = \"data/oresund_vertical_slice.dfsu\"\r\n",
    "mikeio.generic.extract(infile, \"extracted.dfsu\", items='Salinity', end=-2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e = mikeio.read(\"extracted.dfsu\")\r\n",
    "e"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling\n",
    "\n",
    "Adding a constant e.g to adjust datum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds = mikeio.read(\"data/gebco_sound.dfs2\")\r\n",
    "plt.imshow(ds['Elevation'][0])\r\n",
    "plt.colorbar();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds['Elevation'][0,104,131]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the processing step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mikeio.generic.scale(\"data/gebco_sound.dfs2\",\"gebco_sound_local_datum.dfs2\",offset=-2.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds2 = mikeio.read(\"gebco_sound_local_datum.dfs2\")\r\n",
    "plt.imshow(ds2['Elevation'][0])\r\n",
    "plt.colorbar();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds2['Elevation'][0,104,131]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spatially varying correction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "factor = np.ones_like(ds['Elevation'][0])\r\n",
    "factor.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add some spatially varying factors, exaggerated values for educational purpose."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "factor[:,0:100] = 5.3\r\n",
    "factor[0:40,] = 0.1\r\n",
    "factor[150:,150:] = 10.7\r\n",
    "plt.imshow(factor)\r\n",
    "plt.colorbar();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 2d array must first be flipped upside down and then converted to a 1d vector using [numpy.ndarray.flatten](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html) to match how data is stored in dfs files."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "factor_ud = np.flipud(factor)\r\n",
    "factor_vec  = factor_ud.flatten()\r\n",
    "mikeio.generic.scale(\"data/gebco_sound.dfs2\",\"gebco_sound_spatial.dfs2\",factor=factor_vec)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds3 = mikeio.read(\"gebco_sound_spatial.dfs2\")\r\n",
    "plt.imshow(ds3['Elevation'][0])\r\n",
    "plt.colorbar()\r\n",
    "plt.title(\"Spatial correction applied to dfs2\");"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "os.remove(\"concat.dfs1\")\r\n",
    "os.remove(\"extracted.dfs1\")\r\n",
    "os.remove(\"extracted.dfsu\")\r\n",
    "os.remove(\"gebco_sound_local_datum.dfs2\")\r\n",
    "os.remove(\"gebco_sound_spatial.dfs2\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "fa576ebcd40e010bdc0ae86b06ce09151f3424f9e9aed6893ff04f39a9299d89"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}