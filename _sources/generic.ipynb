{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic dfs processing\n",
    "Tools and methods that applies to any type of dfs files. \n",
    "\n",
    "The generic tools are useful for common data processing tasks, where detailed configuration is not necessary. \n",
    "\n",
    "* mikeio.read()\n",
    "* mikeio.generic: methods that read any dfs file and outputs a new dfs file of the same type\n",
    "   - concat: Concatenates files along the time axis  \n",
    "   - scale: Apply scaling to any dfs file\n",
    "   - sum: Sum two dfs files \n",
    "   - diff: Calculate difference between two dfs files\n",
    "   - extract: Extract timesteps and/or items to a new dfs file\n",
    "\n",
    "The generic methods works on larger-than-memory files as they process one time step at a time. This can however make them in-efficient for dfs0 processing! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mikeio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read\n",
    "\n",
    "The mikeio.read() method returns a mikeio [Dataset](https://dhi.github.io/mikeio/understanding_dataset.html) for any dfs file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = mikeio.read(\"data/tide1.dfs1\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at these two files with overlapping timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = mikeio.read(\"data/tide1.dfs1\")\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = mikeio.read(\"data/tide2.dfs1\")\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one of the points along the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t1.time,t1.data[0][:,1], label=\"File 1\")\n",
    "plt.plot(t2.time,t2.data[0][:,1],'k+', label=\"File 2\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mikeio.generic\n",
    "\n",
    "mikeio.generic.concat(infilenames=[\"data/tide1.dfs1\",\n",
    "                                   \"data/tide2.dfs1\"],\n",
    "                     outfilename=\"concat.dfs1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = mikeio.read(\"concat.dfs1\")\n",
    "plt.plot(c.time,c.data[0][:,1])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract time steps or items\n",
    "\n",
    "The extract() method can extract a part of a file:\n",
    "\n",
    "* **time slice** by specifying *start* and/or *end*\n",
    "* specific **items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"data/tide1.dfs1\"\n",
    "mikeio.generic.extract(infile, \"extracted.dfs1\", start='2019-01-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = mikeio.read(\"extracted.dfs1\")\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"data/oresund_vertical_slice.dfsu\"\n",
    "mikeio.generic.extract(infile, \"extracted.dfsu\", items='Salinity', end=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = mikeio.read(\"extracted.dfsu\")\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diff\n",
    "\n",
    "Take difference between two dfs files with same structure - e.g. to see the difference in result between two calibration runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn1 = \"data/oresundHD_run1.dfsu\"\n",
    "fn2 = \"data/oresundHD_run2.dfsu\"\n",
    "fn_diff = \"oresundHD_difference.dfsu\"\n",
    "mikeio.generic.diff(fn1, fn2, fn_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the files and visualize the last time step of the first item (water level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mikeio import Dfsu\n",
    "import matplotlib.pyplot as plt\n",
    "_, ax = plt.subplots(1,3, sharey=True, figsize=(12,5))\n",
    "dfs = Dfsu(fn1)\n",
    "dfs.plot(dfs.read()[0][-1,:], vmin=0.06, vmax=0.27, show_mesh=False, ax=ax[0], title='run 1')\n",
    "dfs = Dfsu(fn2)\n",
    "dfs.plot(dfs.read()[0][-1,:], vmin=0.06, vmax=0.27, show_mesh=False, ax=ax[1], title='run 2')\n",
    "dfs = Dfsu(fn_diff)\n",
    "dfs.plot(dfs.read()[0][-1,:], vmin=-0.1, vmax=0.1, cmap='coolwarm', show_mesh=False, ax=ax[2], title='difference');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Adding a constant e.g to adjust datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = mikeio.read(\"data/gebco_sound.dfs2\")\n",
    "plt.imshow(ds['Elevation'][0])\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Elevation'][0,104,131]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mikeio.generic.scale(\"data/gebco_sound.dfs2\",\"gebco_sound_local_datum.dfs2\",offset=-2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = mikeio.read(\"gebco_sound_local_datum.dfs2\")\n",
    "plt.imshow(ds2['Elevation'][0])\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2['Elevation'][0,104,131]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially varying correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "factor = np.ones_like(ds['Elevation'][0])\n",
    "factor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some spatially varying factors, exaggerated values for educational purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor[:,0:100] = 5.3\n",
    "factor[0:40,] = 0.1\n",
    "factor[150:,150:] = 10.7\n",
    "plt.imshow(factor)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2d array must first be flipped upside down and then converted to a 1d vector using [numpy.ndarray.flatten](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html) to match how data is stored in dfs files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_ud = np.flipud(factor)\n",
    "factor_vec  = factor_ud.flatten()\n",
    "mikeio.generic.scale(\"data/gebco_sound.dfs2\",\"gebco_sound_spatial.dfs2\",factor=factor_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = mikeio.read(\"gebco_sound_spatial.dfs2\")\n",
    "plt.imshow(ds3['Elevation'][0])\n",
    "plt.colorbar()\n",
    "plt.title(\"Spatial correction applied to dfs2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"concat.dfs1\")\n",
    "os.remove(\"extracted.dfs1\")\n",
    "os.remove(\"extracted.dfsu\")\n",
    "os.remove(\"oresundHD_difference.dfsu\")\n",
    "os.remove(\"gebco_sound_local_datum.dfs2\")\n",
    "os.remove(\"gebco_sound_spatial.dfs2\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa576ebcd40e010bdc0ae86b06ce09151f3424f9e9aed6893ff04f39a9299d89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
