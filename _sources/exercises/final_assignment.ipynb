{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Final assignment: Data processing\n",
    "\n",
    "2021-9-14\n",
    "\n",
    "The final exercise involves converting data from one or more providers.\n",
    "\n",
    "Since this exercise is designed to prepare you for real project work, the information you need to solve it might be slightly incomplete or not provided in context. Use your best judgment and most likely your client and your colleagues will be happy ;-)\n",
    "\n",
    "Parts of this assignment can be solved in several ways. Use descriptive variable names and comments or descriptive text if necessary to clarify.\n",
    "The final solution should be clear to your colleagues and will be shared with some of your fellow students for review.\n",
    "\n",
    "The data will be used for MIKE modelling and must be converted to Dfs with **apppropriate EUM types/units** in order to be used by the MIKE software.\n",
    "\n",
    "The data is provided as a [zip file](https://github.com/DHI/getting-started-with-mikeio/raw/main/mini_book/data/stream_data.zip) and two binary files (in the data folder - see FA.3 below).\n",
    "\n",
    "Inside the zip file, there are a many timeseries (ASCII format) of discharge data from streams located across several regions (`*.dat`).\n",
    "\n",
    "Static data for each region is found in a separate file (`region_info.csv`)\n",
    "\n",
    "![](../images/region_info.png)\n",
    "\n",
    "Pandas `read_csv` is very powerful, but here are a few things to keep in mind\n",
    "\n",
    "* Column separator e.g. comma (,)\n",
    "* Blank lines\n",
    "* Comments\n",
    "* Missing values\n",
    "* Date format\n",
    "\n",
    "The MIKE engine can not handle missing values / delete values, **fill in missing values** with interpolated values.\n",
    "\n",
    "In order to save diskspace, **crop the timeseries** to simulation period Feb 1 - June 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FA.1 Convert all timeseries to Dfs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mikeio\n",
    "\n",
    "from mikeio import Dataset\n",
    "from mikeio.eum import EUMType, ItemInfo, EUMUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one way to find and filter filenames in a directory\n",
    "# [x for x in os.listdir(\"datafolder\") if \"some_str\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useful!\n",
    "# help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of reading csv\n",
    "# df = pd.read_csv(\"../data/oceandata.csv\", comment='#', index_col=0, sep=',', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Convert all timeseries to dfs0 (remember that the notebook should be runnable for your peers so put the files somewhere reasonable). \n",
    "\n",
    "b) Read s15_east_novayork_river.dfs0, print the \"header\", plot, and show that the number of missing values is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FA.2 Add region specific info to normalize timeseries with surface area\n",
    "\n",
    "Each timeseries belongs to a region identified in the filename, e.g. `s15_east_novayork_river.dat` is located in the `novayork` region.\n",
    "\n",
    "a) Convert all timeseries to dfs0 with specific discharge, by doing: \n",
    "\n",
    "For each timeseries in the dataset:\n",
    "* Find out which region it belongs to (hint: the string method [split()](https://docs.python.org/3/library/stdtypes.html#str.split) will be useful)\n",
    "* Divide the timeseries values with the surface area for the region (take into account units)\n",
    "* Create a dfs0 file with specific discharge *(discharge / area)* (like the one with discharge from FA.1)\n",
    "\n",
    "b) Determine which station has the largest max specific discharge (in the simulation period).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FA.3 Gridded weather forcing data\n",
    "\n",
    "The dataset is provided in NumPy binary format and consists of\n",
    "\n",
    "* Temperature 2m (degree Kelvin)\n",
    "* Relative humidity 2m (%)\n",
    "\n",
    "The spatial grid is: 40째N - 50째N, 10째E-15째E with a grid spacing of 1 degree in each direction.\n",
    "\n",
    "The time axis consists of two timesteps '2005-01-31', '2005-07-31' which is sufficent to cover the simulation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: these files are in the data folder\n",
    "tmp = np.load(\"../data/temperature_2m.npy\")\n",
    "rh = np.load(\"../data/rel_hum_2m.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = 1.0\n",
    "dx = 1.0\n",
    "time = pd.date_range(\"2005-01-01\", freq='6M', periods=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [tmp, rh]\n",
    "# ds = Dataset(data,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geometry = mikeio.Grid2D(x,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create the Dataset as indicated and write it to a new dfs2 file (check that file appears as the one shown below when opening in MIKE Zero)\n",
    "\n",
    "b) Open the file again and print the header and the longitude, latitude (of the origin)\n",
    "\n",
    "c) Read the data from the file and document that the mean of the relative humidity is the same as the mean of the rh variable above (note: due to rounding errors the may not be exactly the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected outcome when opening the file in MIKE Zero\n",
    "\n",
    "![](../images/weather_dfs2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission of solution\n",
    "\n",
    "Your solution to the above tasks is to be delivered in the format of a single Jupyter notebook file. Please create a new and name it final_assignment_xyz.ipynb where xyz is your initials. It should be easy to understand and runnable by your peers.\n",
    "\n",
    "The solution will be reviewed by three of your fellow students, which will provide feedback on both the correctnes and clarity of your solution.\n",
    "\n",
    "The submission and review process is handled by Campus + Eduflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa576ebcd40e010bdc0ae86b06ce09151f3424f9e9aed6893ff04f39a9299d89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
